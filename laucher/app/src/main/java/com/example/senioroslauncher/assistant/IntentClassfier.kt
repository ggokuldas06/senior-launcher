package com.example.senioroslauncher.assistant

import android.content.Context
import android.util.Log
import com.google.gson.Gson
import com.google.gson.reflect.TypeToken
import org.tensorflow.lite.Interpreter
import java.io.FileInputStream
import java.nio.MappedByteBuffer
import java.nio.channels.FileChannel

/**
 * Intent Classifier using trained TensorFlow Lite model
 * Achieves 98.7% accuracy on 60 intentsR
 */
class IntentClassifier(private val context: Context) {

    private var interpreter: Interpreter? = null
    private val tokenizer = mutableMapOf<String, Int>()
    private val intentMapping = mutableMapOf<Int, String>()
    private val maxLength = 64
    private val vocabSize = 5000

    companion object {
        private const val TAG = "IntentClassifier"
        private const val MODEL_PATH = "models/intent_classifier.tflite"
        private const val TOKENIZER_PATH = "models/tokenizer.json"
        private const val INTENT_MAPPING_PATH = "models/intent_mapping.json"
        const val CONFIDENCE_THRESHOLD = 0.80f
    }

    data class IntentResult(
        val intent: String,
        val confidence: Float,
        val allScores: Map<String, Float>,
        val isAboveThreshold: Boolean = confidence >= CONFIDENCE_THRESHOLD
    )

    /**
     * Initialize the classifier - load model, tokenizer, and intent mapping
     */
    fun initialize(): Result<Unit> {
        return try {
            // Load TFLite model
            val model = loadModelFile()
            val options = Interpreter.Options().apply {
                setNumThreads(4)
//                setUseNNAPI(true) // Hardware acceleration
                addDelegate(org.tensorflow.lite.flex.FlexDelegate())
            }
            interpreter = Interpreter(model, options)
            Log.d(TAG, "✓ TFLite model loaded")

            // Load tokenizer
            loadTokenizer()
            Log.d(TAG, "✓ Tokenizer loaded: ${tokenizer.size} words")

            // Load intent mapping
            loadIntentMapping()
            Log.d(TAG, "✓ Intent mapping loaded: ${intentMapping.size} intents")

            Result.success(Unit)
        } catch (e: Exception) {
            Log.e(TAG, "Failed to initialize classifier", e)
            Result.failure(e)
        }
    }

    /**
     * Classify user input text into intent
     */
    fun classify(text: String): IntentResult {
        try {
            // Preprocess text
            val processed = preprocessText(text)
            if (processed.isBlank()) {
                return IntentResult("UNKNOWN", 0f, emptyMap())
            }

            // Tokenize and pad
            val sequence = tokenize(processed)
            val padded = padSequence(sequence)

            // Convert to float array for TFLite
//            val inputArray = Array(1) { FloatArray(maxLength) { i -> padded[i].toFloat() } }
            val inputArray = Array(1) { IntArray(maxLength) { i -> padded[i] } }
            // Prepare output
            val outputArray = Array(1) { FloatArray(intentMapping.size) }

            // Run inference
            interpreter?.run(inputArray, outputArray)

            // Get results
            val scores = outputArray[0]
            val maxIndex = scores.indices.maxByOrNull { scores[it] } ?: 0
            val maxScore = scores[maxIndex]

            // Map all scores
            val allScores = intentMapping.entries.associate { (index, name) ->
                name to scores[index]
            }

            val intent = intentMapping[maxIndex] ?: "UNKNOWN"

            Log.d(TAG, "Classified: '$text' -> $intent (${maxScore})")

            return IntentResult(
                intent = intent,
                confidence = maxScore,
                allScores = allScores
            )

        } catch (e: Exception) {
            Log.e(TAG, "Classification failed", e)
            return IntentResult("ERROR", 0f, emptyMap())
        }
    }

    private fun loadModelFile(): MappedByteBuffer {
        val fileDescriptor = context.assets.openFd(MODEL_PATH)
        val inputStream = FileInputStream(fileDescriptor.fileDescriptor)
        val fileChannel = inputStream.channel
        val startOffset = fileDescriptor.startOffset
        val declaredLength = fileDescriptor.declaredLength
        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)
    }

    private fun loadTokenizer() {
        val json = context.assets.open(TOKENIZER_PATH).bufferedReader().use { it.readText() }
        val type = object : TypeToken<Map<String, Any>>() {}.type
        val tokenizerJson: Map<String, Any> = Gson().fromJson(json, type)

        @Suppress("UNCHECKED_CAST")
        val wordIndex = tokenizerJson["word_index"] as? Map<String, Double> ?: return

        wordIndex.forEach { (word, index) ->
            tokenizer[word] = index.toInt()
        }
    }

    private fun loadIntentMapping() {
        val json = context.assets.open(INTENT_MAPPING_PATH).bufferedReader().use { it.readText() }
        val type = object : TypeToken<Map<String, String>>() {}.type
        val mappingJson: Map<String, String> = Gson().fromJson(json, type)

        mappingJson.forEach { (key, value) ->
            intentMapping[key.toInt()] = value
        }
    }

    private fun preprocessText(text: String): String {
        // Lowercase and remove special characters
        return text.lowercase()
            .replace(Regex("[^a-z0-9\\s]"), "")
            .trim()
            .replace(Regex("\\s+"), " ")
    }

    private fun tokenize(text: String): List<Int> {
        return text.split(" ")
            .mapNotNull { word -> tokenizer[word] }
            .filter { it < vocabSize }
    }

    private fun padSequence(sequence: List<Int>): IntArray {
        val padded = IntArray(maxLength)
        val length = minOf(sequence.size, maxLength)
        for (i in 0 until length) {
            padded[i] = sequence[i]
        }
        return padded
    }

    /**
     * Check if intent is critical (requires confirmation)
     */
    fun isCriticalIntent(intent: String): Boolean {
        return intent in setOf(
            "SOS_TRIGGER",
            "CALL_CONTACT",
            "MEDICATION_DELETE",
            "MEDICATION_LOG_SKIP",
            "APPOINTMENT_CANCEL",
            "SEND_MESSAGE",
            "CAREGIVER_CONTACT"
        )
    }

    fun close() {
        interpreter?.close()
        Log.d(TAG, "Classifier closed")
    }
}
